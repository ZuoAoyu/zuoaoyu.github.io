<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=theme-color content="dark"><title>keras多分类问题: 新闻主题分类 | 侠客</title><meta property="og:site_name" content="侠客"><meta property="og:title" content="keras多分类问题: 新闻主题分类 | 侠客"><meta itemprop=name content="keras多分类问题: 新闻主题分类 | 侠客"><meta name=twitter:title content="keras多分类问题: 新闻主题分类 | 侠客"><meta name=application-name content="keras多分类问题: 新闻主题分类 | 侠客"><meta name=twitter:card content="summary"><meta name=description content="工作、学习、生活、理想"><meta name=twitter:description content="工作、学习、生活、理想"><meta itemprop=description content="工作、学习、生活、理想"><meta property="og:description" content="工作、学习、生活、理想"><meta property="og:type" content="article"><meta property="article:publisher" content="Guanghao Zuo"><meta property="og:article:published_time" content="2023-05-05T16:29:00+0800"><meta property="article:published_time" content="2023-05-05T16:29:00+0800"><script defer type=application/ld+json>{"@context":"http://schema.org","@type":"Article","headline":"keras多分类问题: 新闻主题分类","author":{"@type":"Person","name":"Guanghao Zuo"},"datePublished":"2023-05-05","description":"","wordCount":1180,"mainEntityOfPage":"True","dateModified":"2023-05-05","publisher":{"@type":"Organization","name":"Guanghao Zuo","logo":{"@type":"imageObject","url":"https:\/\/o5o.me\/favicon.ico"}}}</script><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=stylesheet href=/sass/main.min.ab99ff095f832511e24ffb2fba2b51ad473b2f7e9301d674eba2c6c3a6e8bd81.css></head><script>(function(){const e="ThemeColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="ThemeColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.userColorScheme="dark":document.documentElement.dataset.userColorScheme="light"})()</script><body class=dark><nav class=navbar><div class=container><div class=flex><div><a class=brand href=/><img src=/favicon.ico>
侠客</a></div><div class=flex><a href=/articles/>Articles</a>
<button id=dark-mode-button><svg class="light" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M30.312.776C32 19 20 32 .776 30.312c8.199 7.717 21.091 7.588 29.107-.429C37.9 21.867 38.03 8.975 30.312.776z"/><path d="M30.705 15.915a1.163 1.163.0 101.643 1.641 1.163 1.163.0 00-1.643-1.641zm-16.022 14.38a1.74 1.74.0 000 2.465 1.742 1.742.0 100-2.465zm13.968-2.147a2.904 2.904.0 01-4.108.0 2.902 2.902.0 010-4.107 2.902 2.902.0 014.108.0 2.902 2.902.0 010 4.107z" fill="#ffcc4d"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg><svg class="dark" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M16 2s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2V2zm18 14s2 0 2 2-2 2-2 2h-2s-2 0-2-2 2-2 2-2h2zM4 16s2 0 2 2-2 2-2 2H2s-2 0-2-2 2-2 2-2h2zm5.121-8.707s1.414 1.414.0 2.828-2.828.0-2.828.0L4.878 8.708s-1.414-1.414.0-2.829c1.415-1.414 2.829.0 2.829.0l1.414 1.414zm21 21s1.414 1.414.0 2.828-2.828.0-2.828.0l-1.414-1.414s-1.414-1.414.0-2.828 2.828.0 2.828.0l1.414 1.414zm-.413-18.172s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zm-21 21s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zM16 32s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2v-2z"/><circle fill="#ffd983" cx="18" cy="18" r="10"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg></button></div></div></div></nav><main><div class=container><article><header class=article-header><div class=thumb><div><h1>keras多分类问题: 新闻主题分类</h1><div class=post-meta><div>By Guanghao Zuo | <time>May 05, 2023</time>
| 6 minutes</div><div class=tags><a href=/tags/keras/>Keras</a>
<a href=/tags/%E5%A4%9A%E5%88%86%E7%B1%BB/>多分类</a></div></div></div></div></header></article><div class=article-post><p>所用环境为Colab.</p><h2 id=定义任务目标><a href=#%e5%ae%9a%e4%b9%89%e4%bb%bb%e5%8a%a1%e7%9b%ae%e6%a0%87 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>定义任务目标</h2><p>拿到一些新闻报道, 这些新闻报道都只属于某一个主题, 而不会同时属于多个主题. 把这些新闻报道归类到对应的主题下. 这是一个单标签多分类问题.</p><h2 id=数据收集><a href=#%e6%95%b0%e6%8d%ae%e6%94%b6%e9%9b%86 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据收集</h2><p>使用 路透社 数据集.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 加载数据集(需联网)</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow.keras.datasets</span> <span class=kn>import</span> <span class=n>reuters</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>train_data</span><span class=p>,</span> <span class=n>train_labels</span><span class=p>),</span> <span class=p>(</span><span class=n>test_data</span><span class=p>,</span> <span class=n>test_labels</span><span class=p>)</span> <span class=o>=</span> <span class=n>reuters</span><span class=o>.</span><span class=n>load_data</span><span class=p>(</span><span class=n>num_words</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span> <span class=c1># num_words=10000, 仅保留数据中前10000个最常出现的单词</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=数据可视化><a href=#%e6%95%b0%e6%8d%ae%e5%8f%af%e8%a7%86%e5%8c%96 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据可视化</h4><p>建立对数据形状的感受.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 检查数据</span>
</span></span><span class=line><span class=cl><span class=n>train_data</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>train_labels</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>test_data</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>test_labels</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>train_data</span><span class=o>.</span><span class=n>dtype</span>
</span></span><span class=line><span class=cl><span class=c1># ((8982,), (8982,), (2246,), (2246,), dtype(&#39;O&#39;))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>type</span><span class=p>(</span><span class=n>train_data</span><span class=p>),</span> <span class=nb>type</span><span class=p>(</span><span class=n>train_data</span><span class=p>[</span><span class=mi>0</span><span class=p>]),</span> <span class=n>train_data</span><span class=o>.</span><span class=n>ndim</span>
</span></span><span class=line><span class=cl><span class=c1># (numpy.ndarray, list, 1)</span>
</span></span></code></pre></td></tr></table></div></div><p>看一下数据集里的数据到底长什么样子, 数据对应的标签是什么.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 查看第1条新闻的前10个单词, 以及它的标签(所属主题)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_data</span><span class=p>[</span><span class=mi>0</span><span class=p>][:</span><span class=mi>10</span><span class=p>]</span> <span class=c1># 新闻里的单词被转换为一个个数字.</span>
</span></span><span class=line><span class=cl><span class=c1># [1, 2, 2, 8, 43, 10, 447, 5, 25, 207]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_labels</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 3 该新闻属于第3个分类</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 最长的一条新闻的长度是多少</span>
</span></span><span class=line><span class=cl><span class=nb>max</span><span class=p>([</span><span class=nb>max</span><span class=p>(</span><span class=n>item</span><span class=p>)</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>train_data</span><span class=p>])</span> <span class=c1># 先得到每条新闻的长度, 再得到长度的最大值</span>
</span></span></code></pre></td></tr></table></div></div><p>数据集里的评论被编码为了数字, 解码成正常文本看看.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>word_index</span> <span class=o>=</span> <span class=n>reuters</span><span class=o>.</span><span class=n>get_word_index</span><span class=p>()</span> <span class=c1># word_index 是一个字典, 键是单词, 值是对应的一个整数.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>reverse_word_index</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>([(</span><span class=n>value</span><span class=p>,</span> <span class=n>key</span><span class=p>)</span> <span class=k>for</span> <span class=p>(</span><span class=n>key</span><span class=p>,</span> <span class=n>value</span><span class=p>)</span> <span class=ow>in</span> <span class=n>word_index</span><span class=o>.</span><span class=n>items</span><span class=p>()])</span> <span class=c1># 一个新字典, 键是一个整数, 值是该整数对应的单词</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>decoded_newswire</span> <span class=o>=</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=n>reverse_word_index</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>i</span> <span class=o>-</span> <span class=mi>3</span><span class=p>,</span> <span class=s2>&#34;?&#34;</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>train_data</span><span class=p>[</span><span class=mi>0</span><span class=p>]])</span> <span class=c1># 把训练集中的第一条新闻解码成正常文本. 索引减3是因为, 训练集里的单词对应的整数, 相比于字典, 都向右偏移了3.</span>
</span></span><span class=line><span class=cl><span class=n>decoded_newswire</span>
</span></span></code></pre></td></tr></table></div></div><p>解码出来的文本:</p><pre tabindex=0><code>? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3
</code></pre><h3 id=数据标注><a href=#%e6%95%b0%e6%8d%ae%e6%a0%87%e6%b3%a8 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据标注</h3><p>已标注好</p><h3 id=数据清理><a href=#%e6%95%b0%e6%8d%ae%e6%b8%85%e7%90%86 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据清理</h3><p>无需清理</p><h2 id=选择模型评估方法><a href=#%e9%80%89%e6%8b%a9%e6%a8%a1%e5%9e%8b%e8%af%84%e4%bc%b0%e6%96%b9%e6%b3%95 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>选择模型评估方法</h2><h3 id=评估方法选择><a href=#%e8%af%84%e4%bc%b0%e6%96%b9%e6%b3%95%e9%80%89%e6%8b%a9 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>评估方法选择</h3><p>这里选择精度(accuracy)作为模型评估的指标. 精度, 即正确分类的新闻条数所占比例.</p><p>怎样用? 构建好模型后, 在模型编译阶段, 将<code>model.compile()</code>的<code>metrics</code>参数值设定为<code>["accuracy"]</code></p><h3 id=确定简单基准模型应能超越这个基准><a href=#%e7%a1%ae%e5%ae%9a%e7%ae%80%e5%8d%95%e5%9f%ba%e5%87%86%e6%a8%a1%e5%9e%8b%e5%ba%94%e8%83%bd%e8%b6%85%e8%b6%8a%e8%bf%99%e4%b8%aa%e5%9f%ba%e5%87%86 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>确定简单基准(模型应能超越这个基准)</h3><p>如果为一条新闻随机指定分类, 能分类正确的概率理论上为$\frac{1}{46} \approx 2.17%$, 因此建立的模型的分类正确率应该超过该值.</p><p>对一批数据进行随机分类, 分类正确的比例是多少? 计算一下:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>copy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_labels_copy</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>test_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>test_labels_copy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>hits_array</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>test_labels</span><span class=p>)</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>test_labels_copy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>hits_array</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 0.1731967943009795</span>
</span></span></code></pre></td></tr></table></div></div><p>把标签随机打乱, 和原来的标签进行比较, 得到分类正确的比率为17.32%, 因此, 建立的模型的正确率应超过该值.</p><h2 id=数据预处理><a href=#%e6%95%b0%e6%8d%ae%e9%a2%84%e5%a4%84%e7%90%86 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据预处理</h2><h3 id=数据向量化和规范化><a href=#%e6%95%b0%e6%8d%ae%e5%90%91%e9%87%8f%e5%8c%96%e5%92%8c%e8%a7%84%e8%8c%83%e5%8c%96 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据向量化和规范化</h3><h4 id=数据向量化><a href=#%e6%95%b0%e6%8d%ae%e5%90%91%e9%87%8f%e5%8c%96 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据向量化</h4><p>对文本列表进行multi-hot编码, 将其转换为由0和1组成的向量. 把每条新闻都转换为一个10000维向量, 如果一个单词在该评论里出现, 就把该单词的索引(单词对应的那个整数)对应位置的元素设为1.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>vectorize_sequences</span><span class=p>(</span><span class=n>sequences</span><span class=p>,</span> <span class=n>dimension</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>results</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=n>sequences</span><span class=p>),</span> <span class=n>dimension</span><span class=p>))</span> <span class=c1># 创建一个零矩阵</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>sequence</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sequences</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=n>sequence</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>results</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1.</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_train</span> <span class=o>=</span> <span class=n>vectorize_sequences</span><span class=p>(</span><span class=n>train_data</span><span class=p>)</span> <span class=c1># 将训练数据向量化</span>
</span></span><span class=line><span class=cl><span class=n>x_test</span> <span class=o>=</span> <span class=n>vectorize_sequences</span><span class=p>(</span><span class=n>test_data</span><span class=p>)</span> <span class=c1># 将测试数据向量化</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=标签向量化和规范化><a href=#%e6%a0%87%e7%ad%be%e5%90%91%e9%87%8f%e5%8c%96%e5%92%8c%e8%a7%84%e8%8c%83%e5%8c%96 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>标签向量化和规范化</h3><p>使用one-hot编码(也叫 分类编码 categorical encoding)将标签向量化, 即将每个标签表示为<strong>维数为标签总类别数</strong>(标签一共有46个类别, 则向量的维数就是46)的向量. 该向量的值的特点: 标签索引对应的元素为1, 其余元素均设为0.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 方法1</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>to_one_hot</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>dimension</span><span class=o>=</span><span class=mi>46</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=n>labels</span><span class=p>),</span> <span class=n>dimension</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>labels</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>label</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1.</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_train</span> <span class=o>=</span> <span class=n>to_one_hot</span><span class=p>(</span><span class=n>train_labels</span><span class=p>)</span> <span class=c1># 将训练标签向量化</span>
</span></span><span class=line><span class=cl><span class=n>y_test</span> <span class=o>=</span> <span class=n>to_one_hot</span><span class=p>(</span><span class=n>test_labels</span><span class=p>)</span> <span class=c1># 将测试标签向量化</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方法2</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow.keras.utils</span> <span class=kn>import</span> <span class=n>to_categorical</span>
</span></span><span class=line><span class=cl><span class=n>y_train</span> <span class=o>=</span> <span class=n>to_categorical</span><span class=p>(</span><span class=n>train_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_test</span> <span class=o>=</span> <span class=n>to_categorical</span><span class=p>(</span><span class=n>test_labels</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=处理后><a href=#%e5%a4%84%e7%90%86%e5%90%8e class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>处理后</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>y_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>train_labels</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s2>&#34;float32&#34;</span><span class=p>)</span> <span class=c1># 将标签向量化</span>
</span></span><span class=line><span class=cl><span class=n>y_test</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>test_labels</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s2>&#34;float32&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>x_test</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>x_train</span><span class=o>.</span><span class=n>ndim</span>
</span></span><span class=line><span class=cl><span class=c1># ((8982, 10000), (2246, 10000), 2)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=c1># 第1条评论现在变成了什么样子</span>
</span></span><span class=line><span class=cl><span class=c1># array([0., 1., 1., ..., 0., 0., 0.])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_train</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>y_test</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl><span class=c1># ((8982,), (2246,))</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=处理缺失值><a href=#%e5%a4%84%e7%90%86%e7%bc%ba%e5%a4%b1%e5%80%bc class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>处理缺失值</h3><p>不需要处理缺失值.</p><h3 id=数据划分-训练集-验证集-测试集><a href=#%e6%95%b0%e6%8d%ae%e5%88%92%e5%88%86-%e8%ae%ad%e7%bb%83%e9%9b%86-%e9%aa%8c%e8%af%81%e9%9b%86-%e6%b5%8b%e8%af%95%e9%9b%86 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据划分: 训练集, 验证集, 测试集</h3><p>从训练集中分出一部分作为验证集.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x_val</span> <span class=o>=</span> <span class=n>x_train</span><span class=p>[:</span><span class=mi>1000</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>partial_x_train</span> <span class=o>=</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>1000</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_val</span> <span class=o>=</span> <span class=n>y_train</span><span class=p>[:</span><span class=mi>1000</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>partial_y_train</span> <span class=o>=</span> <span class=n>y_train</span><span class=p>[</span><span class=mi>1000</span><span class=p>:]</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=构建第一个模型><a href=#%e6%9e%84%e5%bb%ba%e7%ac%ac%e4%b8%80%e4%b8%aa%e6%a8%a1%e5%9e%8b class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>构建第一个模型</h2><h3 id=特征选择过滤没有信息量的特征-开发新特征><a href=#%e7%89%b9%e5%be%81%e9%80%89%e6%8b%a9%e8%bf%87%e6%bb%a4%e6%b2%a1%e6%9c%89%e4%bf%a1%e6%81%af%e9%87%8f%e7%9a%84%e7%89%b9%e5%be%81-%e5%bc%80%e5%8f%91%e6%96%b0%e7%89%b9%e5%be%81 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>特征选择(过滤没有信息量的特征; 开发新特征)</h3><p>在本例中特征就是新闻里编码后的单词了.</p><h3 id=选择架构><a href=#%e9%80%89%e6%8b%a9%e6%9e%b6%e6%9e%84 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>选择架构</h3><p>两个中间层, 每层64个单元. 第三层输出预测值.</p><p>层1: Dense层, &ldquo;表示空间"的维数<code>units</code>为<code>64</code>, 激活函数<code>activation</code>为<code>relu</code>.</p><p>层2: Dense层, &ldquo;表示空间"的维数<code>units</code>为<code>64</code>, 激活函数<code>activation</code>为<code>relu</code>.</p><p>层3: Dense层, &ldquo;表示空间"的维数<code>units</code>为<code>46</code>, 激活函数<code>activation</code>为<code>softmax</code>. 输出是一个数组, 数组元素为46个概率值(总和为1), 表示样本目标值等于各类别的可能性.</p><h3 id=训练配置损失函数-批量大小-学习率><a href=#%e8%ae%ad%e7%bb%83%e9%85%8d%e7%bd%ae%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0-%e6%89%b9%e9%87%8f%e5%a4%a7%e5%b0%8f-%e5%ad%a6%e4%b9%a0%e7%8e%87 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>训练配置(损失函数, 批量大小, 学习率)</h3><h4 id=优化器-optimizer><a href=#%e4%bc%98%e5%8c%96%e5%99%a8-optimizer class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>优化器 optimizer</h4><p>这里选<code>rmsprop</code></p><h4 id=损失函数-loss-function><a href=#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0-loss-function class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>损失函数 loss function</h4><p>这里选分类交叉熵损失函数<code>categorical_crossentropy</code></p><h4 id=训练轮数><a href=#%e8%ae%ad%e7%bb%83%e8%bd%ae%e6%95%b0 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>训练轮数</h4><p>这里训练20轮.</p><h4 id=数据批量大小><a href=#%e6%95%b0%e6%8d%ae%e6%89%b9%e9%87%8f%e5%a4%a7%e5%b0%8f class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>数据批量大小</h4><p>批量大小设为512.</p><h3 id=模型构建代码><a href=#%e6%a8%a1%e5%9e%8b%e6%9e%84%e5%bb%ba%e4%bb%a3%e7%a0%81 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>模型构建代码</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow</span> <span class=kn>import</span> <span class=n>keras</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow.keras</span> <span class=kn>import</span> <span class=n>layers</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span>
</span></span><span class=line><span class=cl>  <span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>  <span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>  <span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>46</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;softmax&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 编译模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>optimizer</span><span class=o>=</span><span class=s2>&#34;rmsprop&#34;</span><span class=p>,</span> <span class=n>loss</span><span class=o>=</span><span class=s2>&#34;categorical_crossentropy&#34;</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=拟合模型><a href=#%e6%8b%9f%e5%90%88%e6%a8%a1%e5%9e%8b class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>拟合模型</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>history</span><span class=err> </span><span class=o>=</span><span class=err> </span><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>partial_x_train</span><span class=p>,</span><span class=err> </span><span class=n>partial_y_train</span><span class=p>,</span><span class=err> </span><span class=n>epochs</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span><span class=err> </span><span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span> <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>x_val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>输出:</p><pre tabindex=0><code>Epoch 1/20
16/16 [==============================] - 3s 94ms/step - loss: 2.7054 - accuracy: 0.5150 - val_loss: 1.8234 - val_accuracy: 0.6300
Epoch 2/20
16/16 [==============================] - 1s 58ms/step - loss: 1.5491 - accuracy: 0.6840 - val_loss: 1.4136 - val_accuracy: 0.7010
Epoch 3/20
16/16 [==============================] - 1s 59ms/step - loss: 1.2007 - accuracy: 0.7417 - val_loss: 1.2068 - val_accuracy: 0.7470
Epoch 4/20
16/16 [==============================] - 1s 58ms/step - loss: 0.9851 - accuracy: 0.7928 - val_loss: 1.1092 - val_accuracy: 0.7520
Epoch 5/20
16/16 [==============================] - 1s 58ms/step - loss: 0.8261 - accuracy: 0.8235 - val_loss: 1.0294 - val_accuracy: 0.7940
Epoch 6/20
16/16 [==============================] - 1s 59ms/step - loss: 0.6971 - accuracy: 0.8502 - val_loss: 0.9827 - val_accuracy: 0.7970
Epoch 7/20
16/16 [==============================] - 1s 59ms/step - loss: 0.5887 - accuracy: 0.8711 - val_loss: 0.9479 - val_accuracy: 0.8000
Epoch 8/20
16/16 [==============================] - 1s 79ms/step - loss: 0.4959 - accuracy: 0.8925 - val_loss: 0.9140 - val_accuracy: 0.8050
Epoch 9/20
16/16 [==============================] - 2s 100ms/step - loss: 0.4289 - accuracy: 0.9053 - val_loss: 0.8881 - val_accuracy: 0.8160
Epoch 10/20
16/16 [==============================] - 1s 77ms/step - loss: 0.3663 - accuracy: 0.9182 - val_loss: 0.8877 - val_accuracy: 0.8250
Epoch 11/20
16/16 [==============================] - 1s 55ms/step - loss: 0.3154 - accuracy: 0.9305 - val_loss: 0.8755 - val_accuracy: 0.8110
Epoch 12/20
16/16 [==============================] - 1s 56ms/step - loss: 0.2739 - accuracy: 0.9361 - val_loss: 0.8825 - val_accuracy: 0.8140
Epoch 13/20
16/16 [==============================] - 1s 60ms/step - loss: 0.2457 - accuracy: 0.9430 - val_loss: 0.9108 - val_accuracy: 0.8180
Epoch 14/20
16/16 [==============================] - 1s 58ms/step - loss: 0.2229 - accuracy: 0.9469 - val_loss: 0.8906 - val_accuracy: 0.8170
Epoch 15/20
16/16 [==============================] - 1s 54ms/step - loss: 0.1983 - accuracy: 0.9499 - val_loss: 0.9395 - val_accuracy: 0.8050
Epoch 16/20
16/16 [==============================] - 1s 54ms/step - loss: 0.1820 - accuracy: 0.9534 - val_loss: 0.9114 - val_accuracy: 0.8170
Epoch 17/20
16/16 [==============================] - 1s 55ms/step - loss: 0.1712 - accuracy: 0.9531 - val_loss: 0.9610 - val_accuracy: 0.8070
Epoch 18/20
16/16 [==============================] - 1s 53ms/step - loss: 0.1546 - accuracy: 0.9550 - val_loss: 0.9263 - val_accuracy: 0.8180
Epoch 19/20
16/16 [==============================] - 1s 65ms/step - loss: 0.1473 - accuracy: 0.9557 - val_loss: 0.9865 - val_accuracy: 0.7990
Epoch 20/20
16/16 [==============================] - 1s 52ms/step - loss: 0.1391 - accuracy: 0.9562 - val_loss: 0.9480 - val_accuracy: 0.8160
</code></pre><p>可以看到, 训练了20轮后, 虽然在训练集上的精度达到了<code>0.9480</code>, 但在验证集上, 精度却只有<code>0.8160</code>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>history_dict</span><span class=err> </span><span class=o>=</span><span class=err> </span><span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=err> </span><span class=c1># 一个字典, 键是&#34;指标&#34;; 值是列表, 指标在每轮训练时的值.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>history_dict</span><span class=o>.</span><span class=n>keys</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># dict_keys([&#39;loss&#39;, &#39;accuracy&#39;, &#39;val_loss&#39;, &#39;val_accuracy&#39;])</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=可视化拟合结果><a href=#%e5%8f%af%e8%a7%86%e5%8c%96%e6%8b%9f%e5%90%88%e7%bb%93%e6%9e%9c class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>可视化拟合结果</h3><h4 id=绘制训练损失和验证损失><a href=#%e7%bb%98%e5%88%b6%e8%ae%ad%e7%bb%83%e6%8d%9f%e5%a4%b1%e5%92%8c%e9%aa%8c%e8%af%81%e6%8d%9f%e5%a4%b1 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>绘制训练损失和验证损失</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>history_dict</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>history_dict</span><span class=p>[</span><span class=s2>&#34;loss&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>val_loss</span> <span class=o>=</span> <span class=n>history_dict</span><span class=p>[</span><span class=s2>&#34;val_loss&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>epochs</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>loss</span><span class=p>,</span> <span class=s2>&#34;bo&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Training loss&#34;</span><span class=p>)</span> <span class=c1># &#34;bo&#34;表示蓝色圆点</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>val_loss</span><span class=p>,</span> <span class=s2>&#34;b&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Validation loss&#34;</span><span class=p>)</span> <span class=c1># &#34;b&#34;表示蓝色实线</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Training and validation loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Epochs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span> <span class=c1># 用于为图表添加图例</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=/2023-05-05/20230505171704.png alt width=567 height=455></p><h4 id=绘制训练精度和验证精度><a href=#%e7%bb%98%e5%88%b6%e8%ae%ad%e7%bb%83%e7%b2%be%e5%ba%a6%e5%92%8c%e9%aa%8c%e8%af%81%e7%b2%be%e5%ba%a6 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>绘制训练精度和验证精度</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># import matplotlib.pyplot as plt</span>
</span></span><span class=line><span class=cl><span class=c1># history_dict = history.history</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>clf</span><span class=p>()</span> <span class=c1># 清空图像</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>acc</span> <span class=o>=</span> <span class=n>history_dict</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>val_acc</span> <span class=o>=</span> <span class=n>history_dict</span><span class=p>[</span><span class=s2>&#34;val_accuracy&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># epochs = range(1, len(loss_values) + 1)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>acc</span><span class=p>,</span> <span class=s2>&#34;bo&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Training acc&#34;</span><span class=p>)</span> <span class=c1># &#34;bo&#34;表示蓝色圆点</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>val_acc</span><span class=p>,</span> <span class=s2>&#34;b&#34;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;Validation acc&#34;</span><span class=p>)</span> <span class=c1># &#34;b&#34;表示蓝色实线</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Training and validation accuracy&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Epochs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Accuracy&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span> <span class=c1># 用于为图表添加图例</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=/2023-05-05/20230505155032.png alt width=576 height=455></p><p>从图中看出, 模型在训练到第9轮后, 开始出现过拟合的现象.</p><h2 id=改进模型><a href=#%e6%94%b9%e8%bf%9b%e6%a8%a1%e5%9e%8b class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>改进模型</h2><h3 id=让模型在训练9轮后停止><a href=#%e8%ae%a9%e6%a8%a1%e5%9e%8b%e5%9c%a8%e8%ae%ad%e7%bb%839%e8%bd%ae%e5%90%8e%e5%81%9c%e6%ad%a2 class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>让模型在训练9轮后停止</h3><p>因为模型在训练到第9轮后就开始过拟合, 因此让模型训练9轮, 之后再次评估模型.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 注意, 这次拟合时没有再从训练集中分出一部分做验证, 而是全部用来训练</span>
</span></span><span class=line><span class=cl><span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>9</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=评价模型><a href=#%e8%af%84%e4%bb%b7%e6%a8%a1%e5%9e%8b class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>评价模型</h2><p>前面选择精度(accuracy)作为模型评估的指标, 因此在对模型效果进行评价时, 使用模型在整个测试集上的平均精度.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>test_loss</span><span class=p>,</span> <span class=n>test_acc</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;测试精度: </span><span class=si>{</span><span class=n>test_acc</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 71/71 [==============================] - 0s 4ms/step - loss: 1.0796 - accuracy: 0.7916 测试精度: 0.7916295528411865</span>
</span></span></code></pre></td></tr></table></div></div><p>可以看到, 模型在测试集上的精度为0.7916, 相比于基准精度而言, 表明建立的模型确实是有效果的.</p><h2 id=利用模型进行预测><a href=#%e5%88%a9%e7%94%a8%e6%a8%a1%e5%9e%8b%e8%bf%9b%e8%a1%8c%e9%a2%84%e6%b5%8b class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>利用模型进行预测</h2><p>拿到一条评论, 对它像在上面那样把它编码为一个由0和1组成的向量, 然后用<code>model.predict()</code>进行预测.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>predictions</span><span class=err> </span><span class=o>=</span><span class=err> </span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>predictions</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl><span class=c1># (2246, 46)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>predic_result</span><span class=err> </span><span class=o>=</span><span class=err> </span><span class=p>[</span><span class=n>item</span><span class=o>.</span><span class=n>argmax</span><span class=p>()</span><span class=err> </span><span class=k>for</span><span class=err> </span><span class=n>item</span><span class=err> </span><span class=ow>in</span><span class=err> </span><span class=n>predictions</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>min</span><span class=p>(</span><span class=n>predic_result</span><span class=p>),</span><span class=err> </span><span class=nb>max</span><span class=p>(</span><span class=n>predic_result</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=部署模型><a href=#%e9%83%a8%e7%bd%b2%e6%a8%a1%e5%9e%8b class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg></a>部署模型</h2><p>不部署.</p></div></div><div class=container><nav class="flex container suggested"><a rel=prev href=/post/keras_case_two_classify_film_review/ title="Previous post (older)"><span>Previous</span>
keras二分类问题: 影评是正面还是负面的</a>
<a rel=next href=/post/keras_case_regression_house_price_forecast/ title="Next post (newer)"><span>Next</span>
keras回归问题: 房价预测</a></nav></div><div class=container></div><div class=container><div class=post-comment><div id=vcomments></div><script src=//unpkg.com/valine/dist/Valine.min.js></script>
<script type=text/javascript>new Valine({el:"#vcomments",appId:"aodxhFvcnQZhByjhPdSxKzWH-gzGzoHsz",appKey:"JbXEtUPYPmhJ285n8cIoAnIn",placeholder:"说点什么吧...",visitor:"true"})</script></div></div></main></main><footer class="footer flex"><section class=container><nav class=footer-links><a href=/index.xml>RSS</a></nav></section><script defer src=/ts/features.706a523ba43e6d0427c7fdf2b9d05dbd0920d3f12942b453690b495cb2522743.js data-enable-footnotes=true></script></footer></body></html>